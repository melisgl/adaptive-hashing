@Comment MATH

@article{aldaz2013monotonicity,
  title={A monotonicity property of variances},
  author={Aldaz, JM},
  journal={Statistics \& Probability Letters},
  volume={83},
  number={5},
  pages={1416--1419},
  year={2013},
  publisher={Elsevier}
}
@article{liao2017sharpening,
  title={Sharpening {Jensen}'s Inequality},
  author={Liao, JG and Berg, Arthur},
  journal={The American Statistician},
  year={2017},
  publisher={Taylor \& Francis}
}

@Comment STATISTICS

@article{kullback1951information,
  title={On information and sufficiency},
  author={Kullback, Solomon and Leibler, Richard A},
  journal={The annals of mathematical statistics},
  volume={22},
  number={1},
  pages={79--86},
  year={1951},
  publisher={JSTOR}
}
@article{shannon1959coding,
  title={Coding theorems for a discrete source with a fidelity criterion},
  author={Shannon, Claude E},
  journal={IRE Nat. Conv. Rec},
  volume={4},
  number={142-163},
  pages={1},
  year={1959}
}
@article{csiszar1964informationstheoretische,
  title={Eine informationstheoretische ungleichung und ihre anwendung auf beweis der ergodizitaet von markoffschen ketten},
  author={Csisz{\'a}r, Imre},
  journal={Magyer Tud. Akad. Mat. Kutato Int. Koezl.},
  volume={8},
  pages={85--108},
  year={1964}
}
@misc{siegrist1197random,
  title = {Probability, Mathematical Statistics, Stochastic Processes},
  year={1997},
  author={Kyle Siegrist},
  howpublished = {\url{https://www.randomservices.org/random/urn/Birthday.html}}
}
@article{ionides2008truncated,
  title={Truncated importance sampling},
  author={Ionides, Edward L},
  journal={Journal of Computational and Graphical Statistics},
  volume={17},
  number={2},
  pages={295--311},
  year={2008},
  publisher={Taylor \& Francis}
}
@article{vehtari2015pareto,
  title={Pareto smoothed importance sampling},
  author={Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  journal={arXiv preprint arXiv:1507.02646},
  year={2015}
}
@article{bhattacharya2019bayesian,
  title={Bayesian fractional posteriors},
  author={Bhattacharya, Anirban and Pati, Debdeep and Yang, Yun and others},
  journal={The Annals of Statistics},
  volume={47},
  number={1},
  pages={39--66},
  year={2019},
  publisher={Institute of Mathematical Statistics}
}

@Comment STOCHASTIC OPTIMIZATION

@incollection{robbins1985stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  booktitle={Herbert Robbins Selected Papers},
  pages={102--109},
  year={1985},
  publisher={Springer}
}
@techreport{ruppert1988efficient,
  title={Efficient estimations from a slowly convergent {R}obbins-{M}onro process},
  author={Ruppert, David},
  year={1988},
  institution={Cornell University Operations Research and Industrial Engineering}
}
@article{werbos1990backpropagation,
  title={Backpropagation through time: what it does and how to do it},
  author={Werbos, Paul J},
  journal={Proceedings of the IEEE},
  volume={78},
  number={10},
  pages={1550--1560},
  year={1990},
  publisher={IEEE}
}
@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM journal on control and optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}
@inproceedings{hochreiter1995simplifying,
  title={Simplifying neural nets by discovering flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in neural information processing systems},
  pages={529--536},
  year={1995}
}
@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~â€¦}
}
@book{spall2005introduction,
  title={Introduction to stochastic search and optimization: estimation, simulation, and control},
  author={Spall, James C},
  volume={65},
  year={2005},
  publisher={John Wiley \& Sons}
}
@article{rakhlin2011making,
  title={Making gradient descent optimal for strongly convex stochastic optimization},
  author={Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
  journal={arXiv preprint arXiv:1109.5647},
  year={2011}
}
@article{lacoste2012simpler,
  title={A simpler approach to obtaining an O (1/t) convergence rate for the projected stochastic subgradient method},
  author={Lacoste-Julien, Simon and Schmidt, Mark and Bach, Francis},
  journal={arXiv preprint arXiv:1212.2002},
  year={2012}
}
@inproceedings{shamir2013stochastic,
  title={Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes},
  author={Shamir, Ohad and Zhang, Tong},
  booktitle={International conference on machine learning},
  pages={71--79},
  year={2013},
  organization={PMLR}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}
@article{jain2018parallelizing,
  title={Parallelizing stochastic gradient descent for least squares regression: mini-batching, averaging, and model misspecification},
  author={Jain, Prateek and Kakade, Sham and Kidambi, Rahul and Netrapalli, Praneeth and Sidford, Aaron},
  journal={Journal of Machine Learning Research},
  volume={18},
  year={2018}
}
@article{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}
@article{liu2019variance,
  title={On the variance of the adaptive learning rate and beyond},
  author={Liu, Liyuan and Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Han, Jiawei},
  journal={arXiv preprint arXiv:1908.03265},
  year={2019}
}
@article{guo2022stochastic,
  title={Stochastic weight averaging revisited},
  author={Guo, Hao and Jin, Jiyong and Liu, Bin},
  journal={arXiv preprint arXiv:2201.00519},
  year={2022}
}
@article{martens2020new,
  title={New insights and perspectives on the natural gradient method},
  author={Martens, James},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5776--5851},
  year={2020},
  publisher={JMLRORG}
}

@Comment VARIATIONAL INFERENCE

@article{jordan1999introduction,
  title={An introduction to variational methods for graphical models},
  author={Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
  journal={Machine learning},
  volume={37},
  number={2},
  pages={183--233},
  year={1999},
  publisher={Springer}
}
@article{turner2011two,
  title={Two problems with variational expectation maximisation for time-series models},
  author={Turner, Richard E and Sahani, Maneesh},
  journal={Bayesian Time series models},
  volume={1},
  number={3.1},
  pages={3--1},
  year={2011},
  publisher={Cambridge, UK: Cambridge Univ. Press}
}
@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2348--2356},
  year={2011}
}
@book{art2013mcbook,
   author = {Art B. Owen},
   year = 2013,
   title = {Monte Carlo theory, methods and examples}
}
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}
@article{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  journal={arXiv preprint arXiv:1401.4082},
  year={2014}
}
@article{mnih2014neural,
  title={Neural variational inference and learning in belief networks},
  author={Mnih, Andriy and Gregor, Karol},
  journal={arXiv preprint arXiv:1402.0030},
  year={2014}
}
@inproceedings{titsias2014doubly,
  title={Doubly stochastic variational Bayes for non-conjugate inference},
  author={Titsias, Michalis and L{\'a}zaro-Gredilla, Miguel},
  booktitle={International Conference on Machine Learning},
  pages={1971--1979},
  year={2014}
}
@article{bornschein2014reweighted,
  title={Reweighted wake-sleep},
  author={Bornschein, J{\"o}rg and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2014}
}
@inproceedings{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Diederik P and Salimans, Tim and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2575--2583},
  year={2015}
}
@article{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir},
  journal={arXiv preprint arXiv:1505.05770},
  year={2015}
}
@article{burda2015importance,
  title={Importance weighted autoencoders},
  author={Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1509.00519},
  year={2015}
}
@article{bowman2015generating,
  title={Generating sentences from a continuous space},
  author={Bowman, Samuel R and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew M and Jozefowicz, Rafal and Bengio, Samy},
  journal={arXiv preprint arXiv:1511.06349},
  year={2015}
}
@inproceedings{miao2016neural,
  title={Neural variational inference for text processing},
  author={Miao, Yishu and Yu, Lei and Blunsom, Phil},
  booktitle={International conference on machine learning},
  pages={1727--1736},
  year={2016}
}
@article{mnih2016variational,
  title={Variational inference for monte carlo objectives},
  author={Mnih, Andriy and Rezende, Danilo J},
  journal={arXiv preprint arXiv:1602.06725},
  year={2016}
}
@inproceedings{hoffman2016elbo,
  title={{ELBO} surgery: yet another way to carve up the variational evidence lower bound},
  author={Hoffman, Matthew D and Johnson, Matthew J},
  booktitle={Workshop in Advances in Approximate Bayesian Inference, {NIPS}},
  year={2016}
}
@inproceedings{kingma2016improved,
  title={Improved variational inference with inverse autoregressive flow},
  author={Kingma, Diederik P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4743--4751},
  year={2016}
}
@article{miller2016variational,
  title={Variational boosting: Iteratively refining posterior approximations},
  author={Miller, Andrew C and Foti, Nicholas and Adams, Ryan P},
  journal={arXiv preprint arXiv:1611.06585},
  year={2016}
}
@inproceedings{li2016renyi,
  title={R{\'e}nyi divergence variational inference},
  author={Li, Yingzhen and Turner, Richard E},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1073--1081},
  year={2016}
}
@article{depeweg2016learning,
  title={Learning and policy search in stochastic dynamical systems with bayesian neural networks},
  author={Depeweg, Stefan and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Doshi-Velez, Finale and Udluft, Steffen},
  journal={arXiv preprint arXiv:1605.07127},
  year={2016}
}
@article{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={3738--3746},
  year={2016}
}
@article{cremer2017reinterpreting,
  title={Reinterpreting importance-weighted autoencoders},
  author={Cremer, Chris and Morris, Quaid and Duvenaud, David},
  journal={arXiv preprint arXiv:1704.02916},
  year={2017}
}
@article{alemi2017fixing,
  title={Fixing a broken ELBO},
  author={Alemi, Alexander A and Poole, Ben and Fischer, Ian and Dillon, Joshua V and Saurous, Rif A and Murphy, Kevin},
  journal={arXiv preprint arXiv:1711.00464},
  year={2017}
}
@inproceedings{yang2017improved,
  title={Improved variational autoencoders for text modeling using dilated convolutions},
  author={Yang, Zichao and Hu, Zhiting and Salakhutdinov, Ruslan and Berg-Kirkpatrick, Taylor},
  booktitle={International conference on machine learning},
  pages={3881--3890},
  year={2017},
  organization={PMLR}
}
@inproceedings{roeder2017sticking,
  title = {Sticking the Landing: Simple, Lower-Variance Gradient Estimators for Variational Inference},
  author = {Roeder, Geoffrey and Wu, Yuhuai and Duvenaud, David K},
  booktitle = {Advances in Neural Information Processing Systems 30},
  year = {2017},
}
@inproceedings{dieng2017variational,
  title={Variational Inference via $\chi$ Upper Bound Minimization},
  author={Dieng, Adji Bousso and Tran, Dustin and Ranganath, Rajesh and Paisley, John and Blei, David},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2732--2741},
  year={2017}
}
@inproceedings{maddison2017filtering,
  title={Filtering variational objectives},
  author={Maddison, Chris J and Lawson, John and Tucker, George and Heess, Nicolas and Norouzi, Mohammad and Mnih, Andriy and Doucet, Arnaud and Teh, Yee},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6573--6583},
  year={2017}
}
@inproceedings{van2017neural,
  title={Neural discrete representation learning},
  author={van den Oord, Aaron and Vinyals, Oriol and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6306--6315},
  year={2017}
}
@article{yeung2017tackling,
  title={Tackling over-pruning in variational autoencoders},
  author={Yeung, Serena and Kannan, Anitha and Dauphin, Yann and Fei-Fei, Li},
  journal={arXiv preprint arXiv:1706.03643},
  year={2017}
}
@article{roy2018theory,
  title={Theory and experiments on vector quantized autoencoders},
  author={Roy, Aurko and Vaswani, Ashish and Neelakantan, Arvind and Parmar, Niki},
  journal={arXiv preprint arXiv:1805.11063},
  year={2018}
}
@article{kim2018semi,
  title={Semi-Amortized Variational Autoencoders},
  author={Kim, Yoon and Wiseman, Sam and Miller, Andrew C and Sontag, David and Rush, Alexander M},
  journal={arXiv preprint arXiv:1802.02550},
  year={2018}
}
@inproceedings{DBLP:conf/nips/ShuBZKE18,
  author={Rui Shu and Hung H. Bui and Shengjia Zhao and Mykel J. Kochenderfer and Stefano Ermon},
  title={Amortized Inference Regularization},
  year={2018},
  cdate={1514764800000},
  pages={4398-4407},
  booktitle={NeurIPS},
}
@article{rainforth2018tighter,
  title={Tighter variational bounds are not necessarily better},
  author={Rainforth, Tom and Kosiorek, Adam R and Le, Tuan Anh and Maddison, Chris J and Igl, Maximilian and Wood, Frank and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1802.04537},
  year={2018}
}
@article{nowozin2018debiasing,
  title={Debiasing Evidence Approximations: On Importance-weighted Autoencoders and Jackknife Variational Inference},
  author={Nowozin, Sebastian},
  year={2018}
}
@article{yao2018yes,
  title={Yes, but Did It Work?: Evaluating Variational Inference},
  author={Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
  journal={arXiv preprint arXiv:1802.02538},
  year={2018}
}
@article{klys2018joint,
  title={Joint Importance Sampling for Variational Inference},
  author={Klys, Jack and Bettencourt, Jesse and Duvenaud, David},
  year={2018}
}
@article{tucker2018doubly,
  title={Doubly reparameterized gradient estimators for monte carlo objectives},
  author={Tucker, George and Lawson, Dieterich and Gu, Shixiang and Maddison, Chris J},
  journal={arXiv preprint arXiv:1810.04152},
  year={2018}
}
@article{cremer2018inference,
  title={Inference suboptimality in variational autoencoders},
  author={Cremer, Chris and Li, Xuechen and Duvenaud, David},
  journal={arXiv preprint arXiv:1801.03558},
  year={2018}
}
@article{dieng2018avoiding,
  title={Avoiding latent variable collapse with generative skip models},
  author={Dieng, Adji B and Kim, Yoon and Rush, Alexander M and Blei, David M},
  journal={arXiv preprint arXiv:1807.04863},
  year={2018}
}
@article{zhang2018advances,
  title={Advances in variational inference},
  author={Zhang, Cheng and B{\"u}tepage, Judith and Kjellstr{\"o}m, Hedvig and Mandt, Stephan},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={2008--2026},
  year={2018},
  publisher={IEEE}
}
@misc{phuong2018mutual,
  title={The Mutual Autoencoder: Controlling Information in Latent Code Representations},
  author={Mary Phuong and Max Welling and Nate Kushman and Ryota Tomioka and Sebastian Nowozin},
  year={2018},
  url={https://openreview.net/forum?id=HkbmWqxCZ},
}
@article{zhao2018information,
  title={The information autoencoding family: A lagrangian perspective on latent variable generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  journal={arXiv preprint arXiv:1806.06514},
  year={2018}
}
@inproceedings{he2018lagging,
  title={Lagging Inference Networks and Posterior Collapse in Variational Autoencoders},
  author={Junxian He and Daniel Spokoyny and Graham Neubig and Taylor Berg-Kirkpatrick},
  booktitle={International Conference on Learning Representations},
  year={2019},
}
@inproceedings{tomczak2018vae,
  title={VAE with a VampPrior},
  author={Tomczak, Jakub and Welling, Max},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1214--1223},
  year={2018},
  organization={PMLR}
}
@inproceedings{razavi2018preventing,
  title={Preventing Posterior Collapse with delta-{VAE}s},
  author={Ali Razavi and Aaron van den Oord and Ben Poole and Oriol Vinyals},
  booktitle={International Conference on Learning Representations},
  year={2019},
}
@inproceedings{NEURIPS2018_65b0df23,
  author = {Huang, Chin-Wei and Tan, Shawn and Lacoste, Alexandre and Courville, Aaron C},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {},
  publisher = {Curran Associates, Inc.},
  title = {Improving Explorability in Variational Inference with Annealed Variational Objectives},
  volume = {31},
  year = {2018}
}
@inproceedings{zhao2019infovae,
  title={Infovae: Balancing learning and inference in variational autoencoders},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={5885--5892},
  year={2019}
}
@misc{lucas2019understanding,
  title={Understanding posterior collapse in generative latent variable models},
  author={Lucas, James and Tucker, George and Grosse, Roger and Norouzi, Mohammad},
  year={2019}
}
@article{mccarthy2019improved,
  title={Improved variational neural machine translation by promoting mutual information},
  author={McCarthy, Arya D and Li, Xian and Gu, Jiatao and Dong, Ning},
  journal={arXiv preprint arXiv:1909.09237},
  year={2019}
}
@inproceedings{NEURIPS2019_9bdb8b1f,
  author = {Maal\o e, Lars and Fraccaro, Marco and Li\'{e}vin, Valentin and Winther, Ole},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {},
  title = {BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling},
  volume = {32},
  year = {2019}
}
@inproceedings{rezaabad2020learning,
  title={Learning representations by maximizing mutual information in variational autoencoders},
  author={Rezaabad, Ali Lotfi and Vishwanath, Sriram},
  booktitle={2020 IEEE International Symposium on Information Theory (ISIT)},
  pages={2729--2734},
  year={2020},
  organization={IEEE}
}
@article{serdega2020vmi,
  title={VMI-VAE: Variational Mutual Information Maximization Framework for VAE With Discrete and Continuous Priors},
  author={Serdega, Andriy and Kim, Dae-Shik},
  journal={arXiv preprint arXiv:2005.13953},
  year={2020}
}
@Comment BETA-VAE

@inproceedings{higgins2016beta,
  title={$\beta$-{VAE}: Learning basic visual concepts with a constrained variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  booktitle={International Conference on Machine Learning},
  year={2017}
}
@article{hoffmanbeta,
  title={The $\beta$-{VAE}â€™s Implicit Prior},
  author={Hoffman, Matthew D and Riquelme, Carlos and Johnson, Matthew J},
  journal={{NIPS} Bayesian Deep Learning Workshop},
  year={2016}
}
@article{burgess2018understanding,
  title={Understanding disentangling in $\beta$-{VAE}},
  author={Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1804.03599},
  year={2018}
}

@Comment GAN

@inproceedings{chen2016infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  booktitle={Proceedings of the 30th International Conference on Neural Information Processing Systems},
  pages={2180--2188},
  year={2016}
}

@Comment DROPOUT

@article{hinton2012improving,
  title={Improving neural networks by preventing co-adaptation of feature detectors},
  author={Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R},
  journal={arXiv preprint arXiv:1207.0580},
  year={2012}
}
@inproceedings{wang2013fast,
  title={Fast dropout training},
  author={Wang, Sida and Manning, Christopher},
  booktitle={international conference on machine learning},
  pages={118--126},
  year={2013}
}
@article{warde2013empirical,
  title={An empirical analysis of dropout in piecewise linear networks},
  author={Warde-Farley, David and Goodfellow, Ian J and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6197},
  year={2013}
}
@inproceedings{wan2013regularization,
  title={Regularization of neural networks using dropconnect},
  author={Wan, Li and Zeiler, Matthew and Zhang, Sixin and Le Cun, Yann and Fergus, Rob},
  booktitle={International Conference on Machine Learning},
  pages={1058--1066},
  year={2013}
}
@article{pachitariu2013regularization,
  title={Regularization and nonlinearities for neural language models: when are they needed?},
  author={Pachitariu, Marius and Sahani, Maneesh},
  journal={arXiv preprint arXiv:1301.5650},
  year={2013}
}
@article{bayer2013fast,
  title={On fast dropout and its applicability to recurrent networks},
  author={Bayer, Justin and Osendorfer, Christian and Korhammer, Daniela and Chen, Nutan and Urban, Sebastian and van der Smagt, Patrick},
  journal={arXiv preprint arXiv:1311.0701},
  year={2013}
}
@inproceedings{baldi2013understanding,
  title={Understanding dropout},
  author={Baldi, Pierre and Sadowski, Peter J},
  booktitle={Advances in neural information processing systems},
  pages={2814--2822},
  year={2013}
}
@article{zaremba2014recurrent,
  title={Recurrent neural network regularization},
  author={Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1409.2329},
  year={2014}
}
@article{srivastava2014dropout,
  title={Dropout: A simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}
@inproceedings{gal2016dropout,
  title={Dropout as a Bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}
@inproceedings{gal2016theoretically,
  title={A theoretically grounded application of dropout in recurrent neural networks},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1019--1027},
  year={2016}
}
@inproceedings{Osband2016RiskVU,
  title={Risk versus Uncertainty in Deep Learning: Bayes, Bootstrap and the Dangers of Dropout},
  booktitle = {{NIPS} Bayesian Deep Learning Workshop},
  author={Ian Osband},
  year={2016}
}
@article{semeniuta2016recurrent,
  title={Recurrent dropout without memory loss},
  author={Semeniuta, Stanislau and Severyn, Aliaksei and Barth, Erhardt},
  journal={arXiv preprint arXiv:1603.05118},
  year={2016}
}
@article{DBLP:journals/corr/MaGHYDH16,
  author    = {Xuezhe Ma and
               Yingkai Gao and
               Zhiting Hu and
               Yaoliang Yu and
               Yuntian Deng and
               Eduard H. Hovy},
  title     = {Dropout with Expectation-linear Regularization},
  journal   = {CoRR},
  volume    = {abs/1609.08017},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.08017},
  archivePrefix = {arXiv},
  eprint    = {1609.08017},
  timestamp = {Wed, 07 Jun 2017 14:40:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MaGHYDH16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{zolna2017fraternal,
  title={Fraternal Dropout},
  author={Zolna, Konrad and Arpit, Devansh and Suhubdy, Dendi and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1711.00066},
  year={2017}
}
@inproceedings{gal2017concrete,
  title={Concrete dropout},
  author={Gal, Yarin and Hron, Jiri and Kendall, Alex},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3584--3593},
  year={2017}
}
@article{noh2017regularizing,
  title={Regularizing deep neural networks by noise: Its interpretation and optimization},
  author={Noh, Hyeonwoo and You, Tackgeun and Mun, Jonghwan and Han, Bohyung},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}
@article{melis2018pushing,
  title={Pushing the bounds of dropout},
  author={Melis, G{\'a}bor and Blundell, Charles and Ko{\v{c}}isk{\`y}, Tom{\'a}{\v{s}} and Hermann, Karl Moritz and Dyer, Chris and Blunsom, Phil},
  journal={arXiv preprint arXiv:1805.09208},
  year={2018}
}

@Comment LANGUAGE MODELLING

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@inproceedings{hochreiter1997lstm,
  title={{LSTM} can solve hard long time lag problems},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in neural information processing systems},
  pages={473--479},
  year={1997}
}
@article{marcus1993building,
  title={Building a large annotated corpus of English: The {Penn} Treebank},
  author={Marcus, Mitchell P and Marcinkiewicz, Mary Ann and Santorini, Beatrice},
  journal={Computational linguistics},
  volume={19},
  number={2},
  pages={313--330},
  year={1993},
  publisher={MIT Press}
}
@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2},
  pages={3},
  year={2010}
}
@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}
@article{melis2017state,
  title={On the state of the art of evaluation in neural language models},
  author={Melis, G{\'a}bor and Dyer, Chris and Blunsom, Phil},
  journal={arXiv preprint arXiv:1707.05589},
  year={2017}
}
@article{merity2017regularizing,
  title={Regularizing and optimizing {LSTM} language models},
  author={Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
  journal={arXiv preprint arXiv:1708.02182},
  year={2017}
}
@article{xie2017data,
  title={Data noising as smoothing in neural network language models},
  author={Xie, Ziang and Wang, Sida I and Li, Jiwei and L{\'e}vy, Daniel and Nie, Aiming and Jurafsky, Dan and Ng, Andrew Y},
  journal={arXiv preprint arXiv:1703.02573},
  year={2017}
}
@article{yang2017breaking,
  title={Breaking the softmax bottleneck: a high-rank {RNN} language model},
  author={Yang, Zhilin and Dai, Zihang and Salakhutdinov, Ruslan and Cohen, William W},
  journal={arXiv preprint arXiv:1711.03953},
  year={2017}
}
@article{merity2017revisiting,
  title={Revisiting Activation Regularization for Language {RNNs}},
  author={Merity, Stephen and McCann, Bryan and Socher, Richard},
  journal={arXiv preprint arXiv:1708.01009},
  year={2017}
}
@article{khandelwal2018sharp,
  title={Sharp nearby, fuzzy far away: How neural language models use context},
  author={Khandelwal, Urvashi and He, He and Qi, Peng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1805.04623},
  year={2018}
}
@article{pelsmaeker2019effective,
  title={Effective estimation of deep generative language models},
  author={Pelsmaeker, Tom and Aziz, Wilker},
  journal={arXiv preprint arXiv:1904.08194},
  year={2019}
}
@article{melis2019mogrifier,
  title={Mogrifier {LSTM}},
  author={Melis, G{\'a}bor and Ko{\v{c}}isk{\`y}, Tom{\'a}{\v{s}} and Blunsom, Phil},
  journal={arXiv preprint arXiv:1909.01792},
  year={2019}
}

@Comment NLP

@book{zipf1935psycho,
  title={The psycho-biology of language.},
  author={Zipf, George Kingsley},
  year={1935},
  publisher={Houghton, Mifflin}
}

@Comment NEURAL NETS

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}
@article{pereyra2017regularizing,
  title={Regularizing neural networks by penalizing confident output distributions},
  author={Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, {\L}ukasz and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1701.06548},
  year={2017}
}
@inproceedings{wang2016natural,
  title={Natural-parameter networks: A class of probabilistic neural networks},
  author={Wang, Hao and Xingjian, SHI and Yeung, Dit-Yan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={118--126},
  year={2016}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{dai2019transformer,
  title={{Transformer-XL}: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Cohen, William W and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}
@article{tallec2018can,
  title={Can recurrent neural networks warp time?},
  author={Tallec, Corentin and Ollivier, Yann},
  journal={arXiv preprint arXiv:1804.11188},
  year={2018}
}

@Comment GENERATIVE MODELLING

@article{dinh2016density,
  title={Density estimation using Real {NVP}},
  author={Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  journal={arXiv preprint arXiv:1605.08803},
  year={2016}
}
@article{kingma2018glow,
  title={Glow: Generative Flow with Invertible 1x1 Convolutions},
  author={Kingma, Diederik P and Dhariwal, Prafulla},
  journal={arXiv preprint arXiv:1807.03039},
  year={2018}
}
@misc{huszar2017representation,
  title = {Is maximum likelihood useful for representation learning?},
  year={2017},
  author={Husz{\'a}r, Ferenc},
  howpublished = {\url{http://web.archive.org/web/20190704042553/https://www.inference.vc/maximum-likelihood-for-representation-learning-2/}},
  note = {Accessed: 2020-04-15}
}

@Comment REINFORCEMENT LEARNING

@inproceedings{williams1987class,
  title={A class of gradient-estimation algorithms for reinforcement learning in neural networks},
  author={Williams, R},
  booktitle={Proceedings of the International Conference on Neural Networks},
  pages={II--601},
  year={1987}
}
@article{metelli2020importance,
  title={Importance Sampling Techniques for Policy Optimization},
  author={Metelli, Alberto Maria and Papini, Matteo and Montali, Nico and Restelli, Marcello},
  journal={J. Mach. Learn. Res.},
  volume={21},
  pages={141--1},
  year={2020}
}

@Comment SOFTWARE

@inproceedings{golovin2017google,
  title={Google {Vizier}: A service for black-box optimization},
  author={Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, D},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={1487--1495},
  year={2017},
  organization={ACM}
}
@misc{newman1999sbcl,
  author = {Newman, William},
  title = {{SBCL}: {S}teel {B}ank {C}ommon {L}isp},
  url={https://sbcl.org},
  year = {1999}
}

@Comment HASHING

@article{luhn1953new,
  title={A new method of recording and searching information},
  author={Luhn, Hans Peter},
  journal={American Documentation},
  volume={4},
  number={1},
  pages={14--16},
  year={1953},
  publisher={Wiley Subscription Services, Inc., A Wiley Company New York}
}
@article{gonnet1981expected,
  title={Expected length of the longest probe sequence in hash code searching},
  author={Gonnet, Gaston H},
  journal={Journal of the ACM (JACM)},
  volume={28},
  number={2},
  pages={289--304},
  year={1981},
  publisher={ACM New York, NY, USA}
}
@article{mehlhorn1984randomized,
  title={Randomized and deterministic simulations of PRAMs by parallel machines with restricted granularity of parallel memories},
  author={Mehlhorn, Kurt and Vishkin, Uzi},
  journal={Acta Informatica},
  volume={21},
  pages={339--374},
  year={1984},
  publisher={Springer}
}
@article{fredman1984storing,
  title={Storing a sparse table with 0 (1) worst case access time},
  author={Fredman, Michael L and Koml{\'o}s, J{\'a}nos and Szemer{\'e}di, Endre},
  journal={Journal of the ACM (JACM)},
  volume={31},
  number={3},
  pages={538--544},
  year={1984},
  publisher={ACM New York, NY, USA}
}
@article{dietzfelbinger1994dynamic,
  title={Dynamic perfect hashing: Upper and lower bounds},
  author={Dietzfelbinger, Martin and Karlin, Anna and Mehlhorn, Kurt and Meyer Auf Der Heide, Friedhelm and Rohnert, Hans and Tarjan, Robert E},
  journal={SIAM Journal on Computing},
  volume={23},
  number={4},
  pages={738--761},
  year={1994},
  publisher={SIAM}
}
@book{10.5555/1213024,
  author = {Collins, William},
  title = {Data Structures and the Java Collections Framework},
  year = {2004},
  isbn = {0073022659},
  publisher = {McGraw-Hill Science/Engineering/Math}
}
@misc{jdkstringhashsubsampling,
  title = {{JDK-4045622}: {java.lang.String.hashCode} spec incorrectly describes the hash algorithm},
  key={{JDK} bug database},
  howpublished = {\url{https://archive.fo/LB0wY}},
  note = {Accessed: 2024-04-14},
  year={1997}
}
@misc{integerhashing,
  title = "Integer hashing",
  author = {Bob Jenkins},
  howpublished = {\url{https://web.archive.org/web/20070210182431/http://burtleburtle.net/bob/hash/integer.html}},
  year={2007}
}
@article{pagh2004cuckoo,
  title={Cuckoo hashing},
  author={Pagh, Rasmus and Rodler, Flemming Friche},
  journal={Journal of Algorithms},
  volume={51},
  number={2},
  pages={122--144},
  year={2004},
  publisher={Elsevier}
}
@inproceedings{belazzougui2009hash,
  title={Hash, displace, and compress},
  author={Belazzougui, Djamal and Botelho, Fabiano C and Dietzfelbinger, Martin},
  booktitle={European Symposium on Algorithms},
  pages={682--693},
  year={2009},
  organization={Springer}
}
@inproceedings{aumasson2012siphash,
  title={{SipHash}: a fast short-input {PRF}},
  author={Aumasson, Jean-Philippe and Bernstein, Daniel J},
  booktitle={International Conference on Cryptology in India},
  pages={489--508},
  year={2012},
  organization={Springer}
}
@article{chi2017hashing,
  title={Hashing techniques: A survey and taxonomy},
  author={Chi, Lianhua and Zhu, Xingquan},
  journal={ACM Computing Surveys (Csur)},
  volume={50},
  number={1},
  pages={1--36},
  year={2017},
  publisher={ACM New York, NY, USA}
}
@misc{jdkhashbug,
  title = {{JDK-4669519}: {Hashmap.get()} in {JDK} 1.4 performs very poorly for some hashcodes},
  key={{JDK} bug database},
  howpublished = {\url{https://bugs.java.com/bugdatabase/view_bug?bug_id=4669519}},
  note = {Accessed: 2024-04-14},
  year={2023}
}
@inproceedings{hentschel2022entropy,
  title={Entropy-learned hashing: Constant time hashing with controllable uniformity},
  author={Hentschel, Brian and Sirin, Utku and Idreos, Stratos},
  booktitle={Proceedings of the 2022 International Conference on Management of Data},
  pages={1640--1654},
  year={2022}
}
@article{kakaraparthy2022vip,
  title={{VIP} Hashing -- {A}dapting to Skew in Popularity of Data on the Fly (extended version)},
  author={Kakaraparthy, Aarati and Patel, Jignesh M and Kroth, Brian P and Park, Kwanghyun},
  journal={arXiv preprint arXiv:2206.12380},
  year={2022}
}
@misc{iwrotehtefastesthashtable,
  key = {Probably Dance},
  title = {I Wrote the Fastest Hash Table},
  url = "https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/",
  note = {Accessed: 2024-04-14},
  year = {2017}
}
@misc{rabbithashing,
  key = {Rabbit Hashing},
  title = {Rabbit Hashing},
  url = "https://github.com/tjizep/rabbit",
  note = {Accessed: 2024-04-14},
  year = {2015}
}
@misc{enwiki:1207615479,
  author = "{Wikipedia contributors}",
  title = "Hash table --- {Wikipedia}{,} {The Free Encyclopedia}",
  year = "2024",
  url = "https://en.wikipedia.org/w/index.php?title=Hash_table&oldid=1207615479",
  note = "[Online; accessed 3-March-2024]"
}
@misc{enwiki:1215467221,
  author = "{Wikipedia contributors}",
  title = "{Fowlerâ€“Nollâ€“Vo} hash function --- {Wikipedia}{,} {The Free Encyclopedia}",
  year = "2024",
  howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Fowler%E2%80%93Noll%E2%80%93Vo_hash_function&oldid=1215467221}",
  note = "[Online; accessed 14-April-2024]"
  }

@Comment MISC

@inproceedings{moret1999towards,
  title={Towards a discipline of experimental algorithmics.},
  author={Moret, Bernard ME},
  booktitle={Data structures, near neighbor searches, and methodology},
  pages={197--213},
  year={1999},
  organization={Citeseer}
}
@book{steele1990common,
  title={Common LISP: {T}he language},
  author={Steele, Guy},
  year={1990},
  publisher={Elsevier}
}
@book{dragonbook,
author = {Aho, Alfred V. and Lam, Monica S. and Sethi, Ravi and Ullman, Jeffrey D.},
title = {Compilers: Principles, Techniques, and Tools (2nd Edition)},
year = {2006},
isbn = {0321486811},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA}
}
